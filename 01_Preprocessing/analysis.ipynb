{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing impute gene expression genotype and phenotype enviromnetal variables\n",
    "## Introduction\n",
    "\n",
    "This notebook contains multiple sections that describe the functions utilized in the analysis.\n",
    "- RF_OOB_Dataset function (dataset_model.py)\n",
    "    - from_config\n",
    "    - get_samples\n",
    "    - get_features\n",
    "    - shuffle_data\n",
    "    - train_test_split\n",
    "    - generate_labels\n",
    "    - save_pipeline\n",
    "    - load_pipeline\n",
    "- Feature Engineering Encoder and Imputer\n",
    "  - NumericalImputer function\n",
    "    - Numerical missing value imputer for numerica variable\n",
    "    - Using mean to impute missing value \n",
    "  - CategoricalImputer_Education\n",
    "    - Categorical missing value imputer for Education (FatherEducation, MotherEducation)\n",
    "    - Using mode to impute missing value\n",
    "    - crate new variable called Total_Education \n",
    "        - above Median(average(sum up FatherEducation and MotherEducation)) = 1\n",
    "        - blow Median(average(sum up FatherEducation and MotherEducation)) = 0 \n",
    "  - CatgoricalEncoder_Income\n",
    "    - String to numbers categorical encoder for Income\n",
    "    - {\"<1000\": \"0\", \"10001~20000\": \"1\", \"20001~30000\": \"2\", \"30001~40000\": \"3\", \"40001~50000\": \"4\", \">50001\": \"5\"}\n",
    "\n",
    "============================================================================================================================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. RF_OOB_Dataset function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from  pathlib import Path\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import sys\n",
    "import dataset_model as dm\n",
    "\n",
    "class ExpressionDataset(ABC):\n",
    "    \"\"\" \n",
    "    The base dataset defining the API for datasets in this project\n",
    "    \"\"\"\n",
    "    \n",
    "    @abstractmethod\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Abstract initializer.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @classmethod\n",
    "    @abstractmethod\n",
    "    def from_config(class_object):\n",
    "        \"\"\"\n",
    "        A function to initialize a ExpressionDataset object\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    @abstractmethod\n",
    "    def get_samples(self):\n",
    "        \"\"\"\n",
    "        Return the sample ids for all samples in the dataset\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    @abstractmethod\n",
    "    def get_features(self):\n",
    "        \"\"\"\n",
    "        Return the list of the ids of all the features in the dataset\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    @abstractmethod\n",
    "    def generate_labels(self):\n",
    "        \"\"\"\n",
    "        Process the y matrix for the given phenotype trait\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    @abstractmethod\n",
    "    def save_pipeline(self):\n",
    "         \"\"\"\n",
    "         Save the version of the pipline\n",
    "         \"\"\"\n",
    "         raise NotImplementedError\n",
    "     \n",
    "    @abstractmethod\n",
    "    def load_pipeline(self):\n",
    "         \"\"\"\n",
    "         Load the version of the pipline\n",
    "         \"\"\"\n",
    "         raise NotImplementedError\n",
    "    \n",
    "    \n",
    "\n",
    "class TrainTestSplit(ExpressionDataset):\n",
    "    \"\"\"\n",
    "    A base train_test_split defining the API for train-test splitting\n",
    "    \"\"\"\n",
    "    @abstractmethod\n",
    "    def train_test_split(self,\n",
    "                         train_fraction,\n",
    "                         test_fraction,\n",
    "                         seed):\n",
    "        \"\"\"\n",
    "        Split the dataset into two portion, \n",
    "        as seen in scikit-learn's `train_test_split` function\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    @abstractmethod\n",
    "    def shuffle_data(self, X, y, seed):\n",
    "        \"\"\"\n",
    "        Random shuffle of the samples in X and y\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    \n",
    "class RF_OOB_Dataset(TrainTestSplit):\n",
    "    \"\"\"\n",
    "    A class containing logic used by all the types of gwas datasets for computing out of bag score\n",
    "    The RF_OOB_Dataset inheritance pattern from class ExpressionDataset and TrainTestSplit\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 gwas_gen_dir,\n",
    "                 label_df_dir,\n",
    "                 env_df_dir):\n",
    "        \n",
    "        \"\"\"\n",
    "        An initializer for the class\n",
    "        \"\"\"\n",
    "        \n",
    "        self.all_gen_df = pd.read_csv(gwas_gen_dir, sep=\",\")\n",
    "        self.all_gen_df = self.all_gen_df.drop(['FID','IID'], axis=1)\n",
    "        self.env_df = pd.read_csv(env_df_dir, sep=\"\\t\")\n",
    "        \n",
    "        self.all_gwas_df = pd.concat([self.all_gen_df, self.env_df], axis=1)\n",
    "        self.label_df = pd.read_csv(label_df_dir, sep=\"\\t\")\n",
    "    \n",
    "    @classmethod \n",
    "    def from_config(class_object,\n",
    "                    config_file,\n",
    "                    weight_tissue):\n",
    "        \"\"\"\n",
    "        A function to create a new object from paths to its data\n",
    "        \"\"\"\n",
    "        \n",
    "        data_dir = Path(config_file['dataset']['data_dir'])\n",
    "        gwas_df_dir = data_dir / weight_tissue / (\"predict_expression_\" + weight_tissue + \"_output.csv\")\n",
    "        \n",
    "        return class_object(gwas_df_dir, config_file['dataset']['phentoype_dir'], config_file['dataset']['env_dir'])\n",
    "    \n",
    "    def get_samples(self):\n",
    "        \"\"\"\n",
    "        Return the list of sample accessions for all samples currently available in the dataset\n",
    "        \"\"\"\n",
    "        return list(self.all_gwas_df.index)\n",
    "    \n",
    "    def get_features(self):\n",
    "        \"\"\"\n",
    "        Return the list of the ids of all the features in the currently available in the dataset \n",
    "        \"\"\"\n",
    "        return list(self.all_gwas_df.columns)\n",
    "    \n",
    "    def shuffle_data(self, X, y, seed):\n",
    "        \"\"\"\n",
    "        Random shuffle of the samples in X and y\n",
    "        \"\"\"\n",
    "        \n",
    "        np.random.seed(seed)\n",
    "        idx = np.arange(X.shape[0])\n",
    "        np.random.shuffle(idx)\n",
    "        \n",
    "        return X[idx], y[idx]\n",
    "    \n",
    "    def train_test_split(self, X, y, seed, test_size=0.2):\n",
    "        \"\"\"\n",
    "        Split the data into train and test sets\n",
    "        \"\"\"\n",
    "        \n",
    "        X, y = self.shuffle_data(X, y, seed)\n",
    "        split_i = len(y) - int(len(y)// (1 / test_size))\n",
    "        X_train, X_test = X[:split_i], X[split_i:]\n",
    "        y_train , y_test = y[:split_i], y[split_i:]\n",
    "        \n",
    "        return X_train, X_test, y_train, y_test\n",
    "    \n",
    "    def generate_labels(self, phen_trait):\n",
    "        \"\"\"\n",
    "        Random shuffle of the samples in X and y\n",
    "        \"\"\"\n",
    "        y_given_phen = self.label_df.loc[:, [phen_trait]]\n",
    "        \n",
    "        return y_given_phen\n",
    "    \n",
    "    @staticmethod\n",
    "    def save_pipeline(pipeline_to_save, save_file_name):\n",
    "        \"\"\"\n",
    "        Save the version of the pipline\n",
    "        \"\"\"\n",
    "        joblib.dump(pipeline_to_save, save_file_name)\n",
    "    \n",
    "    @staticmethod\n",
    "    def load_pipeline(pipline_file_path):\n",
    "        \"\"\"\n",
    "        Load the version of the pipline\n",
    "        \"\"\"\n",
    "        pipline_file_path  = joblib.load(filename=pipline_file_path)\n",
    "        return pipline_file_path\n",
    "\n",
    "try:\n",
    "    with open(\"/exeh_4/yuping/Epistasis_Interaction/01_Preprocessing/config.yaml\") as infile:\n",
    "        load_configure = yaml.safe_load(infile)\n",
    "except Exception:\n",
    "        sys.stderr.write(\"Please specify valid yaml file.\")\n",
    "        sys.exit(1)\n",
    "   \n",
    "\n",
    "RF_OOB_Dataset = dm.RF_OOB_Dataset.from_config(config_file=load_configure, \n",
    "                                               weight_tissue=\"Brain_Amygdala\")\n",
    "\n",
    "y_given_raw_df = RF_OOB_Dataset.generate_labels(\"BDS_Total\")\n",
    "\n",
    "\n",
    "X_raw_df = RF_OOB_Dataset.all_gwas_df.values if isinstance(RF_OOB_Dataset.all_gwas_df, pd.DataFrame) else RF_OOB_Dataset.all_gwas_df\n",
    "y_raw_df = y_given_raw_df.values if isinstance(y_given_raw_df, pd.DataFrame) else y_given_raw_df\n",
    "\n",
    "\n",
    "X_train_raw_df, X_test_raw_df, y_train_raw_df, y_test_raw_df = RF_OOB_Dataset.train_test_split(X_raw_df, \n",
    "                                                                                               y_raw_df, seed=1)\n",
    "\n",
    "X_train_df, X_test_df = pd.DataFrame(X_train_raw_df, columns=RF_OOB_Dataset.all_gwas_df.columns), pd.DataFrame(X_test_raw_df, columns=RF_OOB_Dataset.all_gwas_df.columns)\n",
    "y_train_df, y_test_df = pd.DataFrame(y_train_raw_df, columns=[\"BDS_Total\"]), pd.DataFrame(y_test_raw_df, columns=[\"BDS_Total\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Feature Engineering Encoder and Imputer\n",
    "    - NumericalImputer function\n",
    "    - CategoricalImputer_Education\n",
    "    - CatgoricalEncoder_Income\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import pandas as pd\n",
    "import utils\n",
    "\n",
    "\n",
    "class NumericalImputer(BaseEstimator, TransformerMixin):\n",
    "        \"\"\"\n",
    "        Numerical missing value imputer\n",
    "        \"\"\"\n",
    "      \n",
    "        def __init__(self, variable=None):\n",
    "            if not isinstance(variable, list):\n",
    "                self.variables = [variable]\n",
    "            else:\n",
    "                self.variables = variable\n",
    "                \n",
    "        def fit(self, X, y=None):\n",
    "            self.imputer_dict_ = {}\n",
    "            for feature in self.variables:\n",
    "                self.imputer_dict_[feature] = X[feature].mean()\n",
    "            return self\n",
    "        \n",
    "        def transform(self, X):\n",
    "            X =X.copy()\n",
    "            for feature in self.variables:\n",
    "                X[feature].fillna(self.imputer_dict_[feature], inplace=True)\n",
    "            \n",
    "            return X\n",
    "            \n",
    "class CategoricalImputer_Education(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Categorical missing value imputer for Education \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, variables=None):\n",
    "        if not isinstance(variables, list):\n",
    "            self.variables = [variables]\n",
    "        else:\n",
    "            self.variables = variables\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.imputer_dict = {}\n",
    "        X['MotherEducation'].replace(\"#NULL!\", pd.NA, inplace=True)\n",
    "        X['FatherEducation'].replace(\"#NULL!\", pd.NA, inplace=True)\n",
    "        for feature in self.variables:\n",
    "            self.imputer_dict[feature] = X[feature].mode()[0]\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \n",
    "        for feature in self.variables:\n",
    "            X[feature] = X[feature].fillna(self.imputer_dict[feature])\n",
    "        \n",
    "        X['TotalEducation'] = X.apply(lambda x: (int(x['MotherEducation']) + int(x['FatherEducation']))/2, axis=1)\n",
    "        median = X.TotalEducation.median()\n",
    "        X['TotalEducation'] = X['TotalEducation'].apply(lambda x: 0 if x < median else 1)\n",
    "        \n",
    "        return X\n",
    "\n",
    "class CatgoricalEncoder_Income(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    String to numbers categorical encoder for Income\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, variables=None):\n",
    "        if not isinstance(variables, list):\n",
    "            self.variables = [variables]\n",
    "        else:\n",
    "            self.variables = variables\n",
    "    \n",
    "    def fit(self, y=None):\n",
    "        self.imputer_dict = {}\n",
    "        for feature in self.variables:\n",
    "            self.imputer_dict[feature] = {\"<1000\": \"0\",\n",
    "                                          \"10001~20000\": \"1\",\n",
    "                                          \"20001~30000\": \"2\",\n",
    "                                          \"30001~40000\": \"3\",\n",
    "                                          \"40001~50000\": \"4\",\n",
    "                                          \">50001\": \"5\"}\n",
    "        return self  \n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        for feature in self.variables:\n",
    "            X[feature] = X[feature].map(self.imputer_dict[feature])\n",
    "            \n",
    "            if X[feature].isnull().any():\n",
    "                X[feature].replace(\"#NULL!\", pd.NA, inplace=True)\n",
    "                X[feature].fillna(X[feature].mode()[0], inplace=True)\n",
    "        \n",
    "        return X\n",
    "   \n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    CategoricalImputer_Education(variables=['FatherEducation', 'MotherEducation']),\n",
    "    CatgoricalEncoder_Income(variables=['Income'])\n",
    ")\n",
    "\n",
    "save_file_name = utils.construct_filename(\"/exeh_4/yuping/Epistasis_Interaction/01_Preprocessing/results\",\n",
    "                                          \"output\",\n",
    "                                          \".pkl\",\n",
    "                                          \"pipline\",\n",
    "                                          \"version1\")\n",
    "\n",
    "RF_OOB_Dataset.save_pipeline(pipeline, save_file_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yp_r",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
