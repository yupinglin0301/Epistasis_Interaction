{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting Optimal Parameter\n",
    "## Introduction\n",
    "\n",
    "In this notebook, there are several sections that describe the function.\n",
    "- OOB_ParamGridSearch function (gridsearch_model.py)\n",
    "    - Full function of OOB_ParamGridSearch\n",
    "    - Decomposing code for testing\n",
    "      + fit\n",
    "      + fit_score\n",
    "      + oob_score_accuracy\n",
    "- Evaluation function (eval_metrics.py) \n",
    "- RF_OOB_Dataset function (dataset_model.py)\n",
    "    - from_config\n",
    "    - get_samples\n",
    "    - get_features\n",
    "    - shuffle_data\n",
    "    - train_test_split\n",
    "    - generate_labels\n",
    "    - save_pipeline\n",
    "    - load_pipeline\n",
    "- REFACTORED RF_OOB_Dataset function (dataset_model.py)\n",
    "- Group_shuffle_spliu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  OOB_ParamGridSearch function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import eval_metrics\n",
    "\n",
    "class OOB_ParamGridSearch:\n",
    "    def __init__(self, \n",
    "                 estimator, \n",
    "                 param_grid,\n",
    "                 seed,\n",
    "                 n_jobs=-1, \n",
    "                 refit=True, \n",
    "                 task=\"regression\", \n",
    "                 metric=\"mse\"):\n",
    "        \"\"\"\n",
    "        Initializes the OOB_ParamGridSearch class.\n",
    "\n",
    "       \n",
    "        :param estimator (object): The base estimator to be used.\n",
    "        :param param_grid (dict or list of dicts): The parameter grid to search over.\n",
    "        :param seed (int): The random for reproducibility\n",
    "        :param n_jobs (int, optional): The number of jobs to run in parallel. Defaults to -1.\n",
    "        :param refit (bool, optional): Indicates whether to refit the model with the best hyperparameters. Defaults to True.\n",
    "        :param task (str, optional): The task type, either \"classification\" or \"regression\". Defaults to \"classification\".\n",
    "        :param metric (str, optional): The evaluation metric to use. Defaults to \"mse\".\n",
    "        \"\"\"\n",
    "        self.n_jobs = n_jobs\n",
    "        self.seed = seed \n",
    "        self.estimator = estimator\n",
    "        self.param_grid = param_grid\n",
    "        self.refit = refit\n",
    "        self.task = task\n",
    "        self.metric = metric\n",
    "\n",
    "    def fit(self, \n",
    "            X_train, \n",
    "            y_train):\n",
    "        \"\"\"\n",
    "        Fits the model with the given training data using the parameter grid search.\n",
    "\n",
    "        :param X_train (array-like): The input features for training.\n",
    "        :param y_train (array-like): The target values for training.\n",
    "\n",
    "        :return self (object): Returns self.\n",
    "        \"\"\"\n",
    "        params_iterable = list(ParameterGrid(self.param_grid))\n",
    "        parallel = joblib.Parallel(self.n_jobs)\n",
    "\n",
    "        output = parallel(\n",
    "            joblib.delayed(self.fit_and_score)(deepcopy(self.estimator), X_train, y_train, parameters)\n",
    "            for parameters in params_iterable)\n",
    "\n",
    "        output_array = np.array(output)\n",
    "\n",
    "        best_index = np.argmin(output_array)\n",
    "        self.best_score_ = output_array[best_index]\n",
    "        self.best_param_ = params_iterable[best_index]\n",
    "\n",
    "        cv_results = pd.DataFrame(output, columns=['OOB_Error_Score'])\n",
    "        df_params = pd.DataFrame(params_iterable)\n",
    "        cv_results = pd.concat([cv_results, df_params], axis=1)\n",
    "        cv_results[\"params\"] = params_iterable\n",
    "        self.cv_results = (cv_results.\n",
    "                           sort_values(['OOB_Error_Score'], ascending=True).\n",
    "                           reset_index(drop=True))\n",
    "\n",
    "        if self.refit:\n",
    "            # Final fit with best hyperparameters\n",
    "            cv_model = deepcopy(self.estimator)(rseed=self.seed, **self.best_param_)\n",
    "            cv_model.fit(X_train, y_train, feature_weight=None)\n",
    "            self.cv_model = cv_model\n",
    "\n",
    "        return self\n",
    "\n",
    "    def fit_and_score(self, \n",
    "                      estimator, \n",
    "                      X_train, \n",
    "                      y_train, \n",
    "                      parameters):\n",
    "        \"\"\"\n",
    "        Fits the model and calculates the out-of-bag (OOB) error score.\n",
    "\n",
    "        :param estimator (object): The estimator object.\n",
    "        :param X_train (array-like): The input features for training.\n",
    "        :param y_train (array-like): The target values for training.\n",
    "        :param parameters (dict): The hyperparameters to use for fitting the model.\n",
    "\n",
    "        :return oob_error (float): The calculated out-of-bag error score.\n",
    "        \"\"\"\n",
    "        train_model = estimator(rseed=self.seed, **parameters)\n",
    "        train_model.fit(X_train, y_train, feature_weight=None)\n",
    "        oob_error = 1 - self.oob_score_accuracy(train_model, X_train, y_train, task=self.task, metric=self.metric)\n",
    "\n",
    "        return oob_error\n",
    "\n",
    "    def oob_score_accuracy(self, \n",
    "                           rf, \n",
    "                           X_train, \n",
    "                           y_train, \n",
    "                           task, \n",
    "                           metric):\n",
    "        \"\"\"\n",
    "        Calculates the out-of-bag (OOB) score accuracy.\n",
    "\n",
    "       \n",
    "        :param rf (object): The random forest model.\n",
    "        :param X_train (array-like): The input features for training.\n",
    "        :param y_train (array-like): The target values for training.\n",
    "        :param task (str): The task type, either \"classification\" or \"regression\".\n",
    "        :param metric (str): The evaluation metric to use.\n",
    "\n",
    "        :return oob_score (float): The calculated out-of-bag score accuracy.\n",
    "        \"\"\"\n",
    "        from sklearn.ensemble._forest import _generate_unsampled_indices, _get_n_samples_bootstrap\n",
    "\n",
    "        X = X_train.values if isinstance(X_train, pd.DataFrame) else X_train\n",
    "        y = y_train.values if isinstance(y_train, pd.Series) else y_train\n",
    "\n",
    "        if task == \"classification\":\n",
    "            n_samples = len(X)\n",
    "            n_classes = len(np.unique(y))\n",
    "            predictions = np.zeros((n_samples, n_classes))\n",
    "            for tree in getattr(rf, \"model\").estimators_:\n",
    "                n_samples_bootstrap = _get_n_samples_bootstrap(n_samples, n_samples)\n",
    "                unsampled_indices = _generate_unsampled_indices(tree.random_state, n_samples, n_samples_bootstrap)\n",
    "\n",
    "                tree_preds = tree.predict_proba(X[unsampled_indices, :])\n",
    "                predictions[unsampled_indices] += tree_preds\n",
    "\n",
    "            oob_score = eval_metrics.get_evaluation_report(predictions, y, task, metric)\n",
    "\n",
    "            return oob_score\n",
    "\n",
    "        else:\n",
    "            n_samples = len(X)\n",
    "            predictions = np.zeros(n_samples)\n",
    "            n_predictions = np.zeros(n_samples)\n",
    "            for tree in getattr(rf, \"model\").estimators_:\n",
    "                n_samples_bootstrap = _get_n_samples_bootstrap(n_samples, n_samples)\n",
    "                unsampled_indices = _generate_unsampled_indices(tree.random_state, n_samples, n_samples_bootstrap)\n",
    "\n",
    "                tree_preds = tree.predict(X[unsampled_indices, :])\n",
    "                predictions[unsampled_indices] += tree_preds\n",
    "                n_predictions[unsampled_indices] += 1\n",
    "\n",
    "            predictions /= n_predictions\n",
    "\n",
    "            oob_score = eval_metrics.get_evaluation_report(predictions, y, task, metric)\n",
    "\n",
    "            return oob_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "import model as im\n",
    "\n",
    "X, y = make_regression(n_features=4, n_informative=2, random_state=0, shuffle=False)\n",
    "param_grid = {\n",
    "    'n_estimators': [20, 30, 100],\n",
    "    'max_depth': [2, 3]\n",
    "}\n",
    "\n",
    "oob_gridsearch = OOB_ParamGridSearch(n_jobs=1,\n",
    "                                     estimator=im.IterativeRFRegression,\n",
    "                                     param_grid=param_grid,\n",
    "                                     seed=123,\n",
    "                                     refit=True,\n",
    "                                     task=\"regression\",\n",
    "                                     metric=\"mse\")\n",
    "\n",
    "\n",
    "oob_gridsearch.fit(X_train=X, y_train=y)\n",
    "oob_gridsearch.cv_results\n",
    "\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decomposing code for testing\n",
    "+ fit\n",
    "+ fit_score\n",
    "+ oob_score_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn import datasets\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import model as im\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "dataset = datasets.load_iris(as_frame=True)\n",
    "\n",
    "# Separate out the data\n",
    "X = dataset['data']\n",
    "y = dataset['target']\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [20, 30, 100],\n",
    "    'max_depth': [2, 3]\n",
    "}\n",
    "\n",
    "def fit(X, y, param_grid):\n",
    "\n",
    "    params_iterable = list(ParameterGrid(param_grid))\n",
    "\n",
    "    parallel = joblib.Parallel(n_jobs=1)\n",
    "\n",
    "    output = parallel(\n",
    "              joblib.delayed(_fit_and_score)(deepcopy(\n",
    "                im.IterativeRFClassifier), X, y,parameters)\n",
    "            for parameters in params_iterable)\n",
    "\n",
    "\n",
    "    n_candidates = len(params_iterable)\n",
    "    a=np.array(output, dtype=np.float64)\n",
    "\n",
    "    best_index = np.argmin(a)\n",
    "    best_score_ = a[best_index]\n",
    "    best_param_ = params_iterable[best_index]\n",
    "\n",
    "    cv_results = pd.DataFrame(output, columns=['OOB_Error_Score'])\n",
    "    df_params = pd.DataFrame(params_iterable)\n",
    "    cv_results = pd.concat([cv_results, df_params], axis = 1)\n",
    "\n",
    "\n",
    "    cv_results = (cv_results.\n",
    "                  sort_values(['OOB_Error_Score'],ascending=True).\n",
    "                  reset_index(drop=True))\n",
    "\n",
    "    return cv_results\n",
    "\n",
    "def _fit_and_score(estimator, X, y, parameters):\n",
    "\n",
    "\n",
    "    train_model = estimator(rseed=1, **parameters)\n",
    "    train_model.fit(X, y,  feature_weight=None)\n",
    "    oob_error = 1 - oob_score_accuracy(train_model, X, y)\n",
    "\n",
    "    return oob_error\n",
    "\n",
    "\n",
    "def oob_score_accuracy(rf, X, y):\n",
    "    from sklearn.ensemble._forest import _generate_unsampled_indices, _get_n_samples_bootstrap\n",
    "\n",
    "    X = X.values if isinstance(X, pd.DataFrame) else X\n",
    "    y = y.values if isinstance(y, pd.Series) else y\n",
    "\n",
    "    n_samples = len(X)\n",
    "    n_classes = len(np.unique(y))\n",
    "    predictions = np.zeros((n_samples, n_classes))\n",
    "    for tree in getattr(rf, \"model\").estimators_:\n",
    "        n_samples_bootstrap = _get_n_samples_bootstrap(n_samples, n_samples)\n",
    "        unsampled_indices = _generate_unsampled_indices(tree.random_state, n_samples, n_samples_bootstrap)\n",
    "\n",
    "        tree_preds = tree.predict_proba(X[unsampled_indices, :])\n",
    "        predictions[unsampled_indices] += tree_preds\n",
    "\n",
    "    predicted_class_indexs = np.argmax(predictions, axis=1)\n",
    "    predicted_class = [getattr(rf, \"model\").classes_[i] for i in predicted_class_indexs]\n",
    "    \n",
    "    oob_score = np.mean(y == predicted_class)\n",
    "    \n",
    "    return oob_score\n",
    "\n",
    "oob_gridsearch = fit(X, y, param_grid)\n",
    "print(oob_gridsearch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaulation Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "X, y = make_regression(n_features=4, n_informative=2, random_state=0, shuffle=False)\n",
    "regr = RandomForestRegressor(max_depth=2, random_state=0)\n",
    "regr.fit(X, y)\n",
    "prediction = regr.predict(X)\n",
    "\n",
    "def get_evaluation_report(y_pred, y_true, task, metric):\n",
    "    \"\"\"\n",
    "    Get values for common evaluation metrics\n",
    "\n",
    "    :param y_pred: predicted values\n",
    "    :param y_true: true values\n",
    "    :param task: ML task to solve\n",
    "    :param metic: choose specificed metric to assess the performance\n",
    "\n",
    "    :return: dictionary with specificed metrics\n",
    "    \"\"\"\n",
    "   \n",
    "    if task == 'classification':\n",
    "        average = 'micro' if len(np.unique(y_true)) > 2 else 'binary'\n",
    "        eval_report_dict = {\n",
    "            'auroc': sklearn.metrics.roc_auc_score(y_true=y_true, y_pred=y_pred, average=average),\n",
    "            'aupr': sklearn.metrics.average_precision_score(y_true=y_true, y_pred=y_pred, average=average)\n",
    "        }\n",
    "        eval_report_dict = eval_report_dict[metric]\n",
    "    else:\n",
    "        eval_report_dict = {\n",
    "            'mse': sklearn.metrics.mean_squared_error(y_true=y_true, y_pred=y_pred),\n",
    "            'rmse': sklearn.metrics.mean_squared_error(y_true=y_true, y_pred=y_pred, squared=False),\n",
    "            'r2_score': sklearn.metrics.r2_score(y_true=y_true, y_pred=y_pred),\n",
    "        }\n",
    "        eval_report_dict = eval_report_dict[metric]\n",
    "        \n",
    "    return eval_report_dict\n",
    "\n",
    "\n",
    "get_evaluation_report(prediction, y, task=\"regression\",metric=\"mse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RF_OOB_Dataset function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from  pathlib import Path\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import sys\n",
    "\n",
    "class ExpressionDataset(ABC):\n",
    "    \"\"\" \n",
    "    The base dataset defining the API for datasets in this project\n",
    "    \"\"\"\n",
    "    \n",
    "    @abstractmethod\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Abstract initializer.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @classmethod\n",
    "    @abstractmethod\n",
    "    def from_config(class_object):\n",
    "        \"\"\"\n",
    "        A function to initialize a ExpressionDataset object\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    @abstractmethod\n",
    "    def get_samples(self):\n",
    "        \"\"\"\n",
    "        Return the sample ids for all samples in the dataset\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    @abstractmethod\n",
    "    def get_features(self):\n",
    "        \"\"\"\n",
    "        Return the list of the ids of all the features in the dataset\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    @abstractmethod\n",
    "    def generate_labels(self):\n",
    "        \"\"\"\n",
    "        Process the y matrix for the given phenotype trait\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    @abstractmethod\n",
    "    def save_pipeline(self):\n",
    "         \"\"\"\n",
    "         Save the version of the pipline\n",
    "         \"\"\"\n",
    "         raise NotImplementedError\n",
    "     \n",
    "    @abstractmethod\n",
    "    def load_pipeline(self):\n",
    "         \"\"\"\n",
    "         Load the version of the pipline\n",
    "         \"\"\"\n",
    "         raise NotImplementedError\n",
    "    \n",
    "\n",
    "class TrainTestSplit(ExpressionDataset):\n",
    "    \"\"\"\n",
    "    A base train_test_split defining the API for train-test splitting\n",
    "    \"\"\"\n",
    "    @abstractmethod\n",
    "    def train_test_split(self,\n",
    "                         train_fraction,\n",
    "                         test_fraction,\n",
    "                         seed):\n",
    "        \"\"\"\n",
    "        Split the dataset into two portion, \n",
    "        as seen in scikit-learn's `train_test_split` function\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    @abstractmethod\n",
    "    def shuffle_data(self, X, y, seed):\n",
    "        \"\"\"\n",
    "        Random shuffle of the samples in X and y\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    \n",
    "class RF_OOB_Dataset(TrainTestSplit):\n",
    "    \"\"\"\n",
    "    A class containing logic used by all the types of gwas datasets for computing out of bag score\n",
    "    The RF_OOB_Dataset inheritance pattern from class ExpressionDataset and TrainTestSplit\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 gwas_gen_dir,\n",
    "                 label_df_dir,\n",
    "                 env_df_dir):\n",
    "        \n",
    "        \"\"\"\n",
    "        An initializer for the class\n",
    "        \"\"\"\n",
    "        \n",
    "        self.all_gen_df = pd.read_csv(gwas_gen_dir, sep=\",\")\n",
    "        self.all_gen_df = self.all_gen_df.drop(['FID','IID'], axis=1)\n",
    "        self.env_df = pd.read_csv(env_df_dir, sep=\"\\t\")\n",
    "        \n",
    "        self.all_gwas_df = pd.concat([self.all_gen_df, self.env_df], axis=1)\n",
    "        self.label_df = pd.read_csv(label_df_dir, sep=\"\\t\")\n",
    "    \n",
    "    @classmethod \n",
    "    def from_config(class_object,\n",
    "                    config_file,\n",
    "                    weight_tissue):\n",
    "        \"\"\"\n",
    "        A function to create a new object from paths to its data\n",
    "        \"\"\"\n",
    "        \n",
    "        data_dir = Path(config_file['dataset']['data_dir'])\n",
    "        gwas_df_dir = data_dir / weight_tissue / (\"predict_expression_\" + weight_tissue + \"_output.csv\")\n",
    "        \n",
    "        return class_object(gwas_df_dir, config_file['dataset']['phentoype_dir'], config_file['dataset']['env_dir'])\n",
    "    \n",
    "    def get_samples(self):\n",
    "        \"\"\"\n",
    "        Return the list of sample accessions for all samples currently available in the dataset\n",
    "        \"\"\"\n",
    "        return list(self.all_gwas_df.index)\n",
    "    \n",
    "    def get_features(self):\n",
    "        \"\"\"\n",
    "        Return the list of the ids of all the features in the currently available in the dataset \n",
    "        \"\"\"\n",
    "        return list(self.all_gwas_df.columns)\n",
    "    \n",
    "    def shuffle_data(self, X, y, seed):\n",
    "        \"\"\"\n",
    "        Random shuffle of the samples in X and y\n",
    "        \"\"\"\n",
    "        \n",
    "        np.random.seed(seed)\n",
    "        idx = np.arange(X.shape[0])\n",
    "        np.random.shuffle(idx)\n",
    "        \n",
    "        return X[idx], y[idx]\n",
    "    \n",
    "    def train_test_split(self, X, y, seed, test_size=0.2):\n",
    "        \"\"\"\n",
    "        Split the data into train and test sets\n",
    "        \"\"\"\n",
    "        \n",
    "        X, y = self.shuffle_data(X, y, seed)\n",
    "        split_i = len(y) - int(len(y)// (1 / test_size))\n",
    "        X_train, X_test = X[:split_i], X[split_i:]\n",
    "        y_train , y_test = y[:split_i], y[split_i:]\n",
    "        \n",
    "        return X_train, X_test, y_train, y_test\n",
    "    \n",
    "    def generate_labels(self, phen_trait):\n",
    "        \"\"\"\n",
    "        Random shuffle of the samples in X and y\n",
    "        \"\"\"\n",
    "        y_given_phen = self.label_df.loc[:, [phen_trait]]\n",
    "        \n",
    "        return y_given_phen\n",
    "    \n",
    "    @staticmethod\n",
    "    def save_pipeline(pipeline_to_save, save_file_name):\n",
    "        \"\"\"\n",
    "        Save the version of the pipline\n",
    "        \"\"\"\n",
    "        joblib.dump(pipeline_to_save, save_file_name)\n",
    "    \n",
    "    @staticmethod\n",
    "    def load_pipeline(pipline_file_path):\n",
    "        \"\"\"\n",
    "        Load the version of the pipline\n",
    "        \"\"\"\n",
    "        pipline_file_path  = joblib.load(filename=pipline_file_path)\n",
    "        return pipline_file_path\n",
    "\n",
    "\n",
    "try:\n",
    "    with open(\"/exeh_4/yuping/Epistasis_Interaction/02_Select_Parameter_Model/config.yaml\") as infile:\n",
    "        load_configure = yaml.safe_load(infile)\n",
    "except Exception:\n",
    "        sys.stderr.write(\"Please specify valid yaml file.\")\n",
    "        sys.exit(1)\n",
    "   \n",
    "\n",
    "RF_OOB_Dataset = RF_OOB_Dataset.from_config(config_file=load_configure, \n",
    "                                               weight_tissue=\"Brain_Amygdala\")\n",
    "\n",
    "y_given_raw_df = RF_OOB_Dataset.generate_labels(\"BDS_Total\")\n",
    "\n",
    "\n",
    "X_raw_df = RF_OOB_Dataset.all_gwas_df.values if isinstance(RF_OOB_Dataset.all_gwas_df, pd.DataFrame) else RF_OOB_Dataset.all_gwas_df\n",
    "y_raw_df = y_given_raw_df.values if isinstance(y_given_raw_df, pd.DataFrame) else y_given_raw_df\n",
    "\n",
    "\n",
    "X_train_raw_df, X_test_raw_df, y_train_raw_df, y_test_raw_df = RF_OOB_Dataset.train_test_split(X_raw_df, \n",
    "                                                                                               y_raw_df, seed=1)\n",
    "\n",
    "X_train_df, X_test_df = pd.DataFrame(X_train_raw_df, columns=RF_OOB_Dataset.all_gwas_df.columns), pd.DataFrame(X_test_raw_df, columns=RF_OOB_Dataset.all_gwas_df.columns)\n",
    "y_train_df, y_test_df = pd.DataFrame(y_train_raw_df, columns=[\"BDS_Total\"]), pd.DataFrame(y_test_raw_df, columns=[\"BDS_Total\"])\n",
    "\n",
    "print(np.where(y_train_df.BDS_Total.isnull()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:orange\">REFACTORED Here we refactored the RF_OOB_Dataset function  into the `dataset_model.py`  modules.</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from  pathlib import Path\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import sys\n",
    "\n",
    "\n",
    "class ExpressionDataset(ABC):\n",
    "    \"\"\" \n",
    "    The base dataset defining the API for datasets in this project\n",
    "    \"\"\"\n",
    "    \n",
    "    @abstractmethod\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Abstract initializer.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @classmethod\n",
    "    @abstractmethod\n",
    "    def from_config(class_object):\n",
    "        \"\"\"\n",
    "        A function to initialize a ExpressionDataset object\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    @abstractmethod\n",
    "    def get_samples(self):\n",
    "        \"\"\"\n",
    "        Return the sample ids for all samples in the dataset\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    @abstractmethod\n",
    "    def get_features(self):\n",
    "        \"\"\"\n",
    "        Return the list of the ids of all the features in the dataset\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    @abstractmethod\n",
    "    def generate_labels(self):\n",
    "        \"\"\"\n",
    "        Process the y matrix for the given phenotype trait\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    @abstractmethod\n",
    "    def save_pipeline(self):\n",
    "         \"\"\"\n",
    "         Save the version of the pipline\n",
    "         \"\"\"\n",
    "         raise NotImplementedError\n",
    "     \n",
    "    @abstractmethod\n",
    "    def load_pipeline(self):\n",
    "         \"\"\"\n",
    "         Load the version of the pipline\n",
    "         \"\"\"\n",
    "         raise NotImplementedError\n",
    "     \n",
    "class TrainTestSplitMixin():\n",
    "    \"\"\"\n",
    "    A mixin class providing train-test splitting functionality\n",
    "    \"\"\"\n",
    "    \n",
    "    def shuffle_data(self, X, y, seed):\n",
    "       \"\"\"\n",
    "       Random shuffle of the samples in X and y\n",
    "       \"\"\"\n",
    "       np.random.seed(seed)\n",
    "       idx = np.arange(X.shape[0])\n",
    "       np.random.shuffle(idx)\n",
    "       \n",
    "       return X[idx], y[idx]   \n",
    "\n",
    "    def train_test_split(self, X, y, seed, test_size=0.2):\n",
    "        \"\"\"\n",
    "        Split the data into train and test sets\n",
    "        \"\"\"\n",
    "        X, y = self.shuffle_data(X, y, seed)\n",
    "        split_i = len(y) - int(len(y) // (1 / test_size))\n",
    "        X_train, X_test = X[:split_i], X[split_i:]\n",
    "        y_train, y_test = y[:split_i], y[split_i:]\n",
    "        \n",
    "        return X_train, X_test, y_train, y_test\n",
    "\n",
    "class GroupShuffleSplitMixin():\n",
    "    \"\"\"\n",
    "    A mixin class providing group shuffle splitting functionality\n",
    "    \"\"\"\n",
    "    \n",
    "    def group_shuffle_split(self, X, y, groups, seed, n_splits=1 , test_size=0.2):\n",
    "        \"\"\"\n",
    "        Split the data into train and test sets\n",
    "        \"\"\"\n",
    "        \n",
    "        from sklearn.model_selection import GroupShuffleSplit\n",
    "        gss = GroupShuffleSplit(n_splits=n_splits, train_size=test_size, random_state=seed)  \n",
    "        split = gss.split(X, y, groups=groups)\n",
    "        train_ids, test_ids = next(split)\n",
    "        \n",
    "        X_train, X_test = X[train_ids], X[test_ids]\n",
    "        y_train, y_test = y[train_ids], y[test_ids]\n",
    "        \n",
    "        return X_train, X_test, y_train, y_test\n",
    "    \n",
    "\n",
    "class RF_OOB_Dataset(ExpressionDataset, TrainTestSplitMixin, GroupShuffleSplitMixin):\n",
    "    \"\"\"\n",
    "    A class containing logic used by all the types of gwas datasets for computing out of bag score\n",
    "    The RF_OOB_Dataset inheritance pattern from class ExpressionDataset, TrainTestSplitMixin and GropShufflesSplitMixin\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, gwas_gen_dir, label_df_dir, env_df_dir):\n",
    "        \"\"\"\n",
    "        An initializer for the class\n",
    "        \"\"\"\n",
    "        self.all_gen_df = pd.read_csv(gwas_gen_dir, sep=\",\")\n",
    "        self.all_gen_df = self.all_gen_df.drop(['FID', 'IID'], axis=1)\n",
    "        self.env_df = pd.read_csv(env_df_dir, sep=\"\\t\")\n",
    "        self.all_gwas_df = pd.concat([self.all_gen_df, self.env_df], axis=1)\n",
    "        self.label_df = pd.read_csv(label_df_dir, sep=\"\\t\")\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config_file, weight_tissue):\n",
    "        \"\"\"\n",
    "        A function to create a new object from paths to its data\n",
    "        \"\"\"\n",
    "        data_dir = Path(config_file['dataset']['data_dir'])\n",
    "        gwas_df_dir = data_dir / weight_tissue / (\"predict_expression_\" + weight_tissue + \"_output.csv\")\n",
    "        return cls(gwas_df_dir, config_file['dataset']['phentoype_dir'], config_file['dataset']['env_dir'])\n",
    "\n",
    "    def get_samples(self):\n",
    "        \"\"\"\n",
    "        Return the list of sample accessions for all samples currently available in the dataset\n",
    "        \"\"\"\n",
    "        return list(self.all_gwas_df.index)\n",
    "\n",
    "    def get_features(self):\n",
    "        \"\"\"\n",
    "        Return the list of the ids of all the features in the currently available in the dataset \n",
    "        \"\"\"\n",
    "        return list(self.all_gwas_df.columns)\n",
    "\n",
    "    def generate_labels(self, phen_trait):\n",
    "        \"\"\"\n",
    "        Process the y matrix for the given phenotype trait\n",
    "        \"\"\"\n",
    "        y_given_phen = self.label_df.loc[:, [phen_trait]]\n",
    "        return y_given_phen\n",
    "\n",
    "    @staticmethod\n",
    "    def save_pipeline(pipeline_to_save, save_file_name):\n",
    "        \"\"\"\n",
    "        Save the version of the pipeline\n",
    "        \"\"\"\n",
    "        joblib.dump(pipeline_to_save, save_file_name)\n",
    "\n",
    "    @staticmethod\n",
    "    def load_pipeline(pipeline_file_path):\n",
    "        \"\"\"\n",
    "        Load the version of the pipeline\n",
    "        \"\"\"\n",
    "        pipeline = joblib.load(filename=pipeline_file_path)\n",
    "        return pipeline\n",
    "\n",
    "\n",
    "\n",
    "# for train-test splitting\n",
    "try:\n",
    "    with open(\"/exeh_4/yuping/Epistasis_Interaction/02_Select_Parameter_Model/config.yaml\") as infile:\n",
    "        load_configure = yaml.safe_load(infile)\n",
    "except Exception:\n",
    "        sys.stderr.write(\"Please specify valid yaml file.\")\n",
    "        sys.exit(1)\n",
    "   \n",
    "rf_oob_dataset = RF_OOB_Dataset.from_config(config_file=load_configure, \n",
    "                                            weight_tissue=\"Brain_Amygdala\")\n",
    "\n",
    "y_given_raw_df = rf_oob_dataset.generate_labels(\"BDS_Total\")\n",
    "X_raw_df = rf_oob_dataset.all_gwas_df.values if isinstance(rf_oob_dataset.all_gwas_df, pd.DataFrame) else rf_oob_dataset.all_gwas_df\n",
    "y_raw_df = y_given_raw_df.values if isinstance(y_given_raw_df, pd.DataFrame) else y_given_raw_df\n",
    "X_train_raw_df, X_test_raw_df, y_train_raw_df, y_test_raw_df = rf_oob_dataset.train_test_split(X_raw_df,  y_raw_df, seed=1)\n",
    "\n",
    "# group-shuffle split\n",
    "X = np.array([[1, 2], [3], [4], [5, 6], [7, 8], [9, 10], [11, 12]])\n",
    "y = np.array([0, 1, 1, 0, 1, 0, 1])\n",
    "groups = np.array([1, 4, 5, 2, 2, 3, 3])\n",
    "X_train_raw_df, X_test_raw_df, y_train_raw_df, y_test_raw_df = rf_oob_dataset.group_shuffle_split(X, y, groups, seed=123, n_splits=1 , test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Example data\n",
    "X = np.array([[1, 2], [3], [4], [5, 6], [7, 8], [9, 10], [11, 12]])\n",
    "y = np.array([0, 1, 1, 0, 1, 0, 1])\n",
    "groups = np.array([1, 4, 5, 2, 2, 3, 3])\n",
    "\n",
    "# Create a dictionary to store the indices of samples for each group\n",
    "group_indices = {}\n",
    "for idx, group in enumerate(groups):\n",
    "    if group not in group_indices:\n",
    "        group_indices[group] = []\n",
    "    group_indices[group].append(idx)\n",
    "    \n",
    "# Shuffle the indices within each group\n",
    "for group in group_indices:\n",
    "        np.random.shuffle(group_indices[group])\n",
    "\n",
    "# Combine the shuffled indices of all groups   \n",
    "shuffled_indices = np.concatenate(list(group_indices.values()))\n",
    "\n",
    "# Split the shuffled indices into train and test sets\n",
    "train_indices, test_indices = train_test_split(shuffled_indices, test_size=0.2, random_state=6)  \n",
    "X_train = X[train_indices]\n",
    "X_test = X[test_indices]\n",
    "\n",
    "print(X_train)\n",
    "print(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yp_r",
   "language": "python",
   "name": "yp_r"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
